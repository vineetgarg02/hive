PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1_txt
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1_txt
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_1
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2_txt
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2_txt
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_2
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3_txt
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3_txt
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_6_3
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE DECIMAL_6_1_txt(key decimal(10,5), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_6_1_txt
POSTHOOK: query: CREATE TABLE DECIMAL_6_1_txt(key decimal(10,5), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_6_1_txt
PREHOOK: query: CREATE TABLE DECIMAL_6_2_txt(key decimal(17,5), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_6_2_txt
POSTHOOK: query: CREATE TABLE DECIMAL_6_2_txt(key decimal(17,5), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_6_2_txt
PREHOOK: query: CREATE TABLE DECIMAL_6_3_txt(key decimal(10,5), value int, key_big decimal(20,5))
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_6_3_txt
POSTHOOK: query: CREATE TABLE DECIMAL_6_3_txt(key decimal(10,5), value int, key_big decimal(20,5))
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_6_3_txt
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv9.txt' INTO TABLE DECIMAL_6_1_txt
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@decimal_6_1_txt
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv9.txt' INTO TABLE DECIMAL_6_1_txt
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@decimal_6_1_txt
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv9.txt' INTO TABLE DECIMAL_6_2_txt
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@decimal_6_2_txt
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv9.txt' INTO TABLE DECIMAL_6_2_txt
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@decimal_6_2_txt
PREHOOK: query: INSERT INTO DECIMAL_6_3_txt SELECT key, value, key FROM DECIMAL_6_1_txt
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_1_txt
PREHOOK: Output: default@decimal_6_3_txt
POSTHOOK: query: INSERT INTO DECIMAL_6_3_txt SELECT key, value, key FROM DECIMAL_6_1_txt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_1_txt
POSTHOOK: Output: default@decimal_6_3_txt
POSTHOOK: Lineage: decimal_6_3_txt.key SIMPLE [(decimal_6_1_txt)decimal_6_1_txt.FieldSchema(name:key, type:decimal(10,5), comment:null), ]
POSTHOOK: Lineage: decimal_6_3_txt.key_big EXPRESSION [(decimal_6_1_txt)decimal_6_1_txt.FieldSchema(name:key, type:decimal(10,5), comment:null), ]
POSTHOOK: Lineage: decimal_6_3_txt.value SIMPLE [(decimal_6_1_txt)decimal_6_1_txt.FieldSchema(name:value, type:int, comment:null), ]
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT * FROM DECIMAL_6_1_txt where key < 200BD ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT * FROM DECIMAL_6_1_txt where key < 200BD ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: decimal_6_1_txt
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      projectedColumnNums: [0, 1]
                      projectedColumns: [key:decimal(10,5), value:int]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterDecimalColLessDecimalScalar(col 0:decimal(10,5), val 200)
                    predicate: (key < 200) (type: boolean)
                    Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: decimal(10,5)), value (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: decimal(10,5)), _col1 (type: int)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                vectorizationSupportRemovedReasons: [DECIMAL_64 removed because LLAP is enabled]
                vectorizationSupport: []
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:decimal(10,5), value:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:decimal(10,5), KEY.reducesinkkey1:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: decimal(10,5)), KEY.reducesinkkey1 (type: int)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT * FROM DECIMAL_6_1_txt where key < 200BD ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_1_txt
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM DECIMAL_6_1_txt where key < 200BD ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_1_txt
#### A masked pattern was here ####
-4400.00000	4400
-1255.49000	-1255
-1.12200	-11
-1.12000	-1
-0.33300	0
-0.30000	0
0.00000	0
0.00000	0
0.33300	0
1.00000	1
1.00000	1
1.12000	1
1.12200	1
2.00000	2
3.14000	3
3.14000	3
3.14000	4
10.00000	10
10.73433	5
124.00000	124
125.20000	125
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT * FROM DECIMAL_6_1_txt where key - 100BD < 200BD ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT * FROM DECIMAL_6_1_txt where key - 100BD < 200BD ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: decimal_6_1_txt
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      projectedColumnNums: [0, 1]
                      projectedColumns: [key:decimal(10,5), value:int]
                  Filter Operator
                    Filter Vectorization:
                        className: VectorFilterOperator
                        native: true
                        predicateExpression: FilterDecimalColLessDecimalScalar(col 2:decimal(11,5), val 200)(children: DecimalColSubtractDecimalScalar(col 0:decimal(10,5), val 100) -> 2:decimal(11,5))
                    predicate: ((key - 100) < 200) (type: boolean)
                    Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                    Select Operator
                      expressions: key (type: decimal(10,5)), value (type: int)
                      outputColumnNames: _col0, _col1
                      Select Vectorization:
                          className: VectorSelectOperator
                          native: true
                          projectedOutputColumnNums: [0, 1]
                      Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: decimal(10,5)), _col1 (type: int)
                        sort order: ++
                        Reduce Sink Vectorization:
                            className: VectorReduceSinkObjectHashOperator
                            keyColumnNums: [0, 1]
                            native: true
                            nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                            valueColumnNums: []
                        Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                vectorizationSupportRemovedReasons: [DECIMAL_64 removed because LLAP is enabled]
                vectorizationSupport: []
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:decimal(10,5), value:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [decimal(11,5)]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    dataColumns: KEY.reducesinkkey0:decimal(10,5), KEY.reducesinkkey1:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: decimal(10,5)), KEY.reducesinkkey1 (type: int)
                outputColumnNames: _col0, _col1
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1]
                Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT * FROM DECIMAL_6_1_txt where key - 100BD < 200BD ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_1_txt
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM DECIMAL_6_1_txt where key - 100BD < 200BD ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_1_txt
#### A masked pattern was here ####
-4400.00000	4400
-1255.49000	-1255
-1.12200	-11
-1.12000	-1
-0.33300	0
-0.30000	0
0.00000	0
0.00000	0
0.33300	0
1.00000	1
1.00000	1
1.12000	1
1.12200	1
2.00000	2
3.14000	3
3.14000	3
3.14000	4
10.00000	10
10.73433	5
124.00000	124
125.20000	125
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, key - 100BD FROM DECIMAL_6_1_txt ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, key - 100BD FROM DECIMAL_6_1_txt ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: decimal_6_1_txt
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      projectedColumnNums: [0, 1]
                      projectedColumns: [key:decimal(10,5), value:int]
                  Select Operator
                    expressions: key (type: decimal(10,5)), value (type: int), (key - 100) (type: decimal(11,5))
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 2]
                        selectExpressions: DecimalColSubtractDecimalScalar(col 0:decimal(10,5), val 100) -> 2:decimal(11,5)
                    Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: decimal(10,5)), _col1 (type: int)
                      sort order: ++
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0, 1]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [2]
                      Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col2 (type: decimal(11,5))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                vectorizationSupportRemovedReasons: [DECIMAL_64 removed because LLAP is enabled]
                vectorizationSupport: []
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 2
                    includeColumns: [0, 1]
                    dataColumns: key:decimal(10,5), value:int
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [decimal(11,5)]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:decimal(10,5), KEY.reducesinkkey1:int, VALUE._col0:decimal(11,5)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: decimal(10,5)), KEY.reducesinkkey1 (type: int), VALUE._col0 (type: decimal(11,5))
                outputColumnNames: _col0, _col1, _col2
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2]
                Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 1 Data size: 116 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, value, key - 100BD FROM DECIMAL_6_1_txt ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_1_txt
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, value, key - 100BD FROM DECIMAL_6_1_txt ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_1_txt
#### A masked pattern was here ####
NULL	-1234567890	NULL
NULL	0	NULL
NULL	3	NULL
NULL	4	NULL
NULL	1234567890	NULL
-4400.00000	4400	-4500.00000
-1255.49000	-1255	-1355.49000
-1.12200	-11	-101.12200
-1.12000	-1	-101.12000
-0.33300	0	-100.33300
-0.30000	0	-100.30000
0.00000	0	-100.00000
0.00000	0	-100.00000
0.33300	0	-99.66700
1.00000	1	-99.00000
1.00000	1	-99.00000
1.12000	1	-98.88000
1.12200	1	-98.87800
2.00000	2	-98.00000
3.14000	3	-96.86000
3.14000	3	-96.86000
3.14000	4	-96.86000
10.00000	10	-90.00000
10.73433	5	-89.26567
124.00000	124	24.00000
125.20000	125	25.20000
23232.23435	2	23132.23435
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, key - 100BD, key_big FROM DECIMAL_6_3_txt ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, key - 100BD, key_big FROM DECIMAL_6_3_txt ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: decimal_6_3_txt
                  Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      projectedColumnNums: [0, 1, 2]
                      projectedColumns: [key:decimal(10,5), value:int, key_big:decimal(20,5)]
                  Select Operator
                    expressions: key (type: decimal(10,5)), value (type: int), (key - 100) (type: decimal(11,5)), key_big (type: decimal(20,5))
                    outputColumnNames: _col0, _col1, _col2, _col3
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 3, 2]
                        selectExpressions: DecimalColSubtractDecimalScalar(col 0:decimal(10,5), val 100) -> 3:decimal(11,5)
                    Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: decimal(10,5)), _col1 (type: int)
                      sort order: ++
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0, 1]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [3, 2]
                      Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col2 (type: decimal(11,5)), _col3 (type: decimal(20,5))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                vectorizationSupportRemovedReasons: [DECIMAL_64 removed because LLAP is enabled]
                vectorizationSupport: []
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    includeColumns: [0, 1, 2]
                    dataColumns: key:decimal(10,5), value:int, key_big:decimal(20,5)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [decimal(11,5)]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 4
                    dataColumns: KEY.reducesinkkey0:decimal(10,5), KEY.reducesinkkey1:int, VALUE._col0:decimal(11,5), VALUE._col1:decimal(20,5)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: decimal(10,5)), KEY.reducesinkkey1 (type: int), VALUE._col0 (type: decimal(11,5)), VALUE._col1 (type: decimal(20,5))
                outputColumnNames: _col0, _col1, _col2, _col3
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3]
                Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, value, key - 100BD, key_big FROM DECIMAL_6_3_txt ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_3_txt
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, value, key - 100BD, key_big FROM DECIMAL_6_3_txt ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_3_txt
#### A masked pattern was here ####
NULL	-1234567890	NULL	NULL
NULL	0	NULL	NULL
NULL	3	NULL	NULL
NULL	4	NULL	NULL
NULL	1234567890	NULL	NULL
-4400.00000	4400	-4500.00000	-4400.00000
-1255.49000	-1255	-1355.49000	-1255.49000
-1.12200	-11	-101.12200	-1.12200
-1.12000	-1	-101.12000	-1.12000
-0.33300	0	-100.33300	-0.33300
-0.30000	0	-100.30000	-0.30000
0.00000	0	-100.00000	0.00000
0.00000	0	-100.00000	0.00000
0.33300	0	-99.66700	0.33300
1.00000	1	-99.00000	1.00000
1.00000	1	-99.00000	1.00000
1.12000	1	-98.88000	1.12000
1.12200	1	-98.87800	1.12200
2.00000	2	-98.00000	2.00000
3.14000	3	-96.86000	3.14000
3.14000	3	-96.86000	3.14000
3.14000	4	-96.86000	3.14000
10.00000	10	-90.00000	10.00000
10.73433	5	-89.26567	10.73433
124.00000	124	24.00000	124.00000
125.20000	125	25.20000	125.20000
23232.23435	2	23132.23435	23232.23435
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, key - 100BD, key_big, key_big - key FROM DECIMAL_6_3_txt ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, key - 100BD, key_big, key_big - key FROM DECIMAL_6_3_txt ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: decimal_6_3_txt
                  Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      projectedColumnNums: [0, 1, 2]
                      projectedColumns: [key:decimal(10,5), value:int, key_big:decimal(20,5)]
                  Select Operator
                    expressions: key (type: decimal(10,5)), value (type: int), (key - 100) (type: decimal(11,5)), key_big (type: decimal(20,5)), (key_big - key) (type: decimal(21,5))
                    outputColumnNames: _col0, _col1, _col2, _col3, _col4
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 3, 2, 4]
                        selectExpressions: DecimalColSubtractDecimalScalar(col 0:decimal(10,5), val 100) -> 3:decimal(11,5), DecimalColSubtractDecimalColumn(col 2:decimal(20,5), col 0:decimal(10,5)) -> 4:decimal(21,5)
                    Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: decimal(10,5)), _col1 (type: int)
                      sort order: ++
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0, 1]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [3, 2, 4]
                      Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col2 (type: decimal(11,5)), _col3 (type: decimal(20,5)), _col4 (type: decimal(21,5))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                vectorizationSupportRemovedReasons: [DECIMAL_64 removed because LLAP is enabled]
                vectorizationSupport: []
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    includeColumns: [0, 1, 2]
                    dataColumns: key:decimal(10,5), value:int, key_big:decimal(20,5)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [decimal(11,5), decimal(21,5)]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 5
                    dataColumns: KEY.reducesinkkey0:decimal(10,5), KEY.reducesinkkey1:int, VALUE._col0:decimal(11,5), VALUE._col1:decimal(20,5), VALUE._col2:decimal(21,5)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: decimal(10,5)), KEY.reducesinkkey1 (type: int), VALUE._col0 (type: decimal(11,5)), VALUE._col1 (type: decimal(20,5)), VALUE._col2 (type: decimal(21,5))
                outputColumnNames: _col0, _col1, _col2, _col3, _col4
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2, 3, 4]
                Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 27 Data size: 6156 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, value, key - 100BD, key_big, key_big - key FROM DECIMAL_6_3_txt ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_3_txt
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, value, key - 100BD, key_big, key_big - key FROM DECIMAL_6_3_txt ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_3_txt
#### A masked pattern was here ####
NULL	-1234567890	NULL	NULL	NULL
NULL	0	NULL	NULL	NULL
NULL	3	NULL	NULL	NULL
NULL	4	NULL	NULL	NULL
NULL	1234567890	NULL	NULL	NULL
-4400.00000	4400	-4500.00000	-4400.00000	0.00000
-1255.49000	-1255	-1355.49000	-1255.49000	0.00000
-1.12200	-11	-101.12200	-1.12200	0.00000
-1.12000	-1	-101.12000	-1.12000	0.00000
-0.33300	0	-100.33300	-0.33300	0.00000
-0.30000	0	-100.30000	-0.30000	0.00000
0.00000	0	-100.00000	0.00000	0.00000
0.00000	0	-100.00000	0.00000	0.00000
0.33300	0	-99.66700	0.33300	0.00000
1.00000	1	-99.00000	1.00000	0.00000
1.00000	1	-99.00000	1.00000	0.00000
1.12000	1	-98.88000	1.12000	0.00000
1.12200	1	-98.87800	1.12200	0.00000
2.00000	2	-98.00000	2.00000	0.00000
3.14000	3	-96.86000	3.14000	0.00000
3.14000	3	-96.86000	3.14000	0.00000
3.14000	4	-96.86000	3.14000	0.00000
10.00000	10	-90.00000	10.00000	0.00000
10.73433	5	-89.26567	10.73433	0.00000
124.00000	124	24.00000	124.00000	0.00000
125.20000	125	25.20000	125.20000	0.00000
23232.23435	2	23132.23435	23232.23435	0.00000
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, cast(key as decimal(20,4)) FROM DECIMAL_6_3_txt ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, cast(key as decimal(20,4)) FROM DECIMAL_6_3_txt ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: decimal_6_3_txt
                  Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      projectedColumnNums: [0, 1, 2]
                      projectedColumns: [key:decimal(10,5), value:int, key_big:decimal(20,5)]
                  Select Operator
                    expressions: key (type: decimal(10,5)), value (type: int), CAST( key AS decimal(20,4)) (type: decimal(20,4))
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 3]
                        selectExpressions: CastDecimalToDecimal(col 0:decimal(10,5)) -> 3:decimal(20,4)
                    Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: decimal(10,5)), _col1 (type: int)
                      sort order: ++
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0, 1]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [3]
                      Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col2 (type: decimal(20,4))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                vectorizationSupportRemovedReasons: [DECIMAL_64 removed because LLAP is enabled]
                vectorizationSupport: []
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    includeColumns: [0, 1]
                    dataColumns: key:decimal(10,5), value:int, key_big:decimal(20,5)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [decimal(20,4)]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:decimal(10,5), KEY.reducesinkkey1:int, VALUE._col0:decimal(20,4)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: decimal(10,5)), KEY.reducesinkkey1 (type: int), VALUE._col0 (type: decimal(20,4))
                outputColumnNames: _col0, _col1, _col2
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2]
                Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, value, cast(key as decimal(20,4)) FROM DECIMAL_6_3_txt ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_3_txt
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, value, cast(key as decimal(20,4)) FROM DECIMAL_6_3_txt ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_3_txt
#### A masked pattern was here ####
NULL	-1234567890	NULL
NULL	0	NULL
NULL	3	NULL
NULL	4	NULL
NULL	1234567890	NULL
-4400.00000	4400	-4400.0000
-1255.49000	-1255	-1255.4900
-1.12200	-11	-1.1220
-1.12000	-1	-1.1200
-0.33300	0	-0.3330
-0.30000	0	-0.3000
0.00000	0	0.0000
0.00000	0	0.0000
0.33300	0	0.3330
1.00000	1	1.0000
1.00000	1	1.0000
1.12000	1	1.1200
1.12200	1	1.1220
2.00000	2	2.0000
3.14000	3	3.1400
3.14000	3	3.1400
3.14000	4	3.1400
10.00000	10	10.0000
10.73433	5	10.7343
124.00000	124	124.0000
125.20000	125	125.2000
23232.23435	2	23232.2344
PREHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, key * value FROM DECIMAL_6_3_txt ORDER BY key, value
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN VECTORIZATION DETAIL
SELECT key, value, key * value FROM DECIMAL_6_3_txt ORDER BY key, value
POSTHOOK: type: QUERY
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Tez
#### A masked pattern was here ####
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: decimal_6_3_txt
                  Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                  TableScan Vectorization:
                      native: true
                      projectedColumnNums: [0, 1, 2]
                      projectedColumns: [key:decimal(10,5), value:int, key_big:decimal(20,5)]
                  Select Operator
                    expressions: key (type: decimal(10,5)), value (type: int), (key * CAST( value AS decimal(10,0))) (type: decimal(21,5))
                    outputColumnNames: _col0, _col1, _col2
                    Select Vectorization:
                        className: VectorSelectOperator
                        native: true
                        projectedOutputColumnNums: [0, 1, 4]
                        selectExpressions: DecimalColMultiplyDecimalColumn(col 0:decimal(10,5), col 3:decimal(10,0))(children: CastLongToDecimal(col 1:int) -> 3:decimal(10,0)) -> 4:decimal(21,5)
                    Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                    Reduce Output Operator
                      key expressions: _col0 (type: decimal(10,5)), _col1 (type: int)
                      sort order: ++
                      Reduce Sink Vectorization:
                          className: VectorReduceSinkObjectHashOperator
                          keyColumnNums: [0, 1]
                          native: true
                          nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true, No PTF TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                          valueColumnNums: [4]
                      Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                      value expressions: _col2 (type: decimal(21,5))
            Execution mode: vectorized, llap
            LLAP IO: no inputs
            Map Vectorization:
                enabled: true
                enabledConditionsMet: hive.vectorized.use.vector.serde.deserialize IS true
                vectorizationSupportRemovedReasons: [DECIMAL_64 removed because LLAP is enabled]
                vectorizationSupport: []
                inputFileFormats: org.apache.hadoop.mapred.TextInputFormat
                allNative: true
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    includeColumns: [0, 1]
                    dataColumns: key:decimal(10,5), value:int, key_big:decimal(20,5)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: [decimal(10,0), decimal(21,5)]
        Reducer 2 
            Execution mode: vectorized, llap
            Reduce Vectorization:
                enabled: true
                enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true, hive.execution.engine tez IN [tez, spark] IS true
                reduceColumnNullOrder: aa
                reduceColumnSortOrder: ++
                allNative: false
                usesVectorUDFAdaptor: false
                vectorized: true
                rowBatchContext:
                    dataColumnCount: 3
                    dataColumns: KEY.reducesinkkey0:decimal(10,5), KEY.reducesinkkey1:int, VALUE._col0:decimal(21,5)
                    partitionColumnCount: 0
                    scratchColumnTypeNames: []
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: decimal(10,5)), KEY.reducesinkkey1 (type: int), VALUE._col0 (type: decimal(21,5))
                outputColumnNames: _col0, _col1, _col2
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumnNums: [0, 1, 2]
                Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 27 Data size: 3132 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT key, value, key * value FROM DECIMAL_6_3_txt ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_6_3_txt
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, value, key * value FROM DECIMAL_6_3_txt ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_6_3_txt
#### A masked pattern was here ####
NULL	-1234567890	NULL
NULL	0	NULL
NULL	3	NULL
NULL	4	NULL
NULL	1234567890	NULL
-4400.00000	4400	-19360000.00000
-1255.49000	-1255	1575639.95000
-1.12200	-11	12.34200
-1.12000	-1	1.12000
-0.33300	0	0.00000
-0.30000	0	0.00000
0.00000	0	0.00000
0.00000	0	0.00000
0.33300	0	0.00000
1.00000	1	1.00000
1.00000	1	1.00000
1.12000	1	1.12000
1.12200	1	1.12200
2.00000	2	4.00000
3.14000	3	9.42000
3.14000	3	9.42000
3.14000	4	12.56000
10.00000	10	100.00000
10.73433	5	53.67165
124.00000	124	15376.00000
125.20000	125	15650.00000
23232.23435	2	46464.46870
